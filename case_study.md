# Case-study оптимизации процесса формирования отчета

## Актуальная проблема
В рамках проекта существует задача по формированию отчета в формате `json` из входных данных,
содержащих такую информацию, как:  
1 Количество сессий пользователей и различную информацию о них    
2 Время, проведенное пользователями на сайте  
3 Браузеры, используемые пользователями  
4 Даты сессий пользователей  
Программа достаточно быстро формирует необходимый отчет, но при попытке создать отчет на
относительно больших данных (~ 130 мб) отчет формируется неопределенно долгое время. В результате
была поставлена задача по оптимизации формирования данного отчета

## Формирование метрики
Было выдвинуто предположение, что отчет формируется неопределнно долгое время из-за некорректной
работы с памятью и, как следствие, с большой нагрузкой на GC. В связи с этим в качестве метрики
был принят объем памяти, потребляемый в течение работы программы.
В качестве бюджета оптимизации был выбран объем памяти в 70 МБ.

## Гарантия работы оптимизированной программы
В программе уже написаны тесты на существующий функционал. В случае необходимости дополнительные
тесты будут написаны с использованием библиотеки RSpec.

## Feedback-Loop
Для эффективной оптимизации был выстроен следующий `feedback-loop`: Профилирование с использованием
`ruby-prof` или аналогичных профилировщиков -> Оптимизация -> Проверка работы программы с 
использованием тестов -> Закрепление результатов оптимизации с помощью тестов, написанных с
использованием библиотеки `rspec-benchmark`

## Подготовка к анализу точек роста
Так как без оптимизации работы программы дождаться ее окончания проблематчино, было решено сократить
оригинальный файл для анализа точек роста. Для этого были использованы `head` и `tail` следующим
образом: `head -50002 data_large.txt > data_sample.txt`. Чтобы подобрать нужное количество строк
для того, чтобы перенести последего пользователя со всей информацие о нем была использована
команда `head -50002 data_large.txt | tail`. Для дальнейшего анализа ассимптотики был подготовлен
набор сэмпл файлов длиной ~ 10_000, 20_000, 30_000, 40_000 и 50_000 строк. Также для удобства 
профилирования в был переделан метод `work`. Теперь он принимает название файла в качестве 
аргумента. А сам вызов метода был вынесен в отдельный файл `run.rb` для дальнейшего профилирования.

## Анализ ассимптотики
Для анализа ассимптотики были подготовлены файлы вида `data_sample_количество_строк`. В результате
анализа ассимптотики были получены следующие результаты:  
1 Файл на 10_000 строк - 75 МБ  
2 Файл на 20_000 строк - 98 МБ; разница с предыдущим файлом 23 МБ  
3 Файл на 30_000 строк - 118 МБ; разница с предыдущим файлом 20 МБ  
4 Файл на 40_000 строк - 139 МБ; разница с предыдущим файлом 21 МБ  
5 Файл на 50_000 строк - 160 МБ; разница с предыдущим файлом 21 МБ  
Исходя из полученных данных с учетом возможной погрешности был сделан вывод о том, что ассимптотика
примерно линейная.  
Не смотря на то, что основной метрикой был выбран объем памяти, занимаемой программой, стоит 
отметить, что при увелечении количества строк в файле непропорционально увеличивалось время работы
программы.  
Также понятно, что уже файл на 10_000 строк занимает больший объем памяти, чем заложенный в бюджете
оптимизации (основной файл занимает 3_250_940 строк).

## Анализ точек роста
Для анализа основных точек роста был взять сэмпл файл на 50_000 строк. Также основной метод был
дополнен возможностью отключения GC в случае необходимости. Было решено начать анализ точек роста
используя различный отчеты, полученный с помощью библиотеки `ruby-prof`.

### Анализ аллокаций памяти с помощью библиотеки `ruby-prof`
Для начала было решено проанализировать memory allocations с использованием отчетов `ruby-prof`
`flat`, `graph` и `callstack`. К сожалению, от `flat` отчета было мало пользы, но уже отчет `graph`
показал важные результаты.  
Согласно результатам отчета `graph` большую часть memory allocation вызывают методы 
`Object#collect_stats_from_users` и часть вызовов `Array#each`. Пройде по цепочке 
`Object#collect_stats_from_users` было выяснено, что большую часть аллокаций вызывает 
`<Class::Date>#parse` и `Object#parse_session`. Также скорее всего тяжелые по аллокациям вызовы 
`Array#each` вызываются из `Object#collect_stats_from_users`.  
Отчет `callstack` показал приблизительно ту же картину, однако более наглядно. Также стало понятно,
что в какой-то момент точкой роста станет формирования файла .json с помощью 
`JSON::Ext::Generator::GeneratorMethods::Hash#to_json`.

### Анализ аллокаций памяти с помощью библиотеки `stackprof`
Для полноты анализа аллокаций было решено использовать еще и библиотеку `stackprof`. Был построен
текстовый отчет `stackprof` и отчет в виде flamegraph, который затем был проанализирован с помощью
speedscope.app. Эти отчеты показали те же результаты

### Анализ потребления памяти с помощью инструмена callgrind библиотеки `ruby-prof`
Так как callgrind зарекомендовал себя, как крайне удобный инструмент при оптимизации программы по
CPU, было решено использовать и его. Помимо указанных выше точек роста, было выяснено, что в 
методе `Object#parse_session` большую часть памяти занимает `String::split`. Также было выяснено,
что довольно большое количество памяти занимает `Hash::merge`, вызываемый по цепочке из 
`Object#collect_stats_from_users` и `Object::work`.

### Оптимизация парсинга файла
Было решено начать с оптимизации парсинга файла. Сначала был использован метод `String#start_with?`
вместо `String#split` для анализа строчек в файле. Подобная замена привела к снижению потребляемой
памяти на сэмпле с 28 до 24 МБ. Для закрепления результата оптимизации был создан небольшей сэмпл
данных для тестов и созданы тесты на потребление памяти.